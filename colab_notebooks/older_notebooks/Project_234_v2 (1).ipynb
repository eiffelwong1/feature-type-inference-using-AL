{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4yzwH6hW0d7",
    "outputId": "46404182-729e-48e7-f189-8cc0afd5565a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: modAL in /home/siw011/.local/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.9/site-packages (from modAL) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18 in /opt/conda/lib/python3.9/site-packages (from modAL) (1.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /opt/conda/lib/python3.9/site-packages (from modAL) (0.24.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from modAL) (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.1.0->modAL) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas>=1.1.0->modAL) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->modAL) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18->modAL) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.18->modAL) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install modAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aubVrU9VVqoE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import *\n",
    "from modAL.batch import uncertainty_batch_sampling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVVSF_H5VqoF",
    "outputId": "f400f55d-7e7e-4aa0-b8ef-68bca2bc4d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7936, 33)\n",
      "(1985, 33)\n",
      "Index(['Record_id', 'Attribute_name', 'y_act', 'total_vals', 'num_nans',\n",
      "       '%_nans', 'num_of_dist_val', '%_dist_val', 'mean', 'std_dev', 'min_val',\n",
      "       'max_val', 'sample_1', 'sample_2', 'sample_3', 'sample_4', 'sample_5',\n",
      "       'has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count',\n",
      "       'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total',\n",
      "       'mean_char_count', 'stdev_char_count', 'mean_whitespace_count',\n",
      "       'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count',\n",
      "       'is_list', 'is_long_sentence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "xtrain = pd.read_csv('./data_train.csv')\n",
    "xtest = pd.read_csv('./data_test.csv')\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "C7SFzayyVqoG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:310: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filePathName = './RandomForest.pkl'\n",
    "loaded_model = pickle.load(open(filePathName, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YfaMFCF-VqoG"
   },
   "outputs": [],
   "source": [
    "useStats = 1\n",
    "useAttributeName = 1\n",
    "useSample1 = 0\n",
    "useSample2 = 0\n",
    "## Using descriptive stats and attribute name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VovEeB7zVqoH"
   },
   "outputs": [],
   "source": [
    "dict_label = {\n",
    "    'numeric': 0,\n",
    "    'categorical': 1,\n",
    "    'datetime': 2,\n",
    "    'sentence': 3,\n",
    "    'url': 4,\n",
    "    'embedded-number': 5,\n",
    "    'list': 6,\n",
    "    'not-generalizable': 7,\n",
    "    'context-specific': 8\n",
    "}\n",
    "\n",
    "y_train = xtrain.loc[:,['y_act']]\n",
    "y_test = xtest.loc[:,['y_act']]\n",
    "y_train['y_act'] = [dict_label[i] for i in y_train['y_act']]\n",
    "y_test['y_act'] = [dict_label[i] for i in y_test['y_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gN2HUGcVqoH",
    "outputId": "4d1b9a7c-e705-4afd-f17f-50fee930ca53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936 7936\n",
      "7936 7936 7936 7936\n",
      "7936\n",
      "1985 1985\n",
      "1985 1985 1985 1985\n",
      "1985\n"
     ]
    }
   ],
   "source": [
    "def ProcessStats(data,y):\n",
    "\n",
    "    data1 = data[['total_vals', 'num_nans', '%_nans', 'num_of_dist_val', '%_dist_val', 'mean', 'std_dev', 'min_val', 'max_val','has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count',\n",
    "       'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total',\n",
    "       'mean_char_count', 'stdev_char_count', 'mean_whitespace_count',\n",
    "       'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count',\n",
    "       'is_list', 'is_long_sentence']]\n",
    "    data1 = data1.reset_index(drop=True)\n",
    "    data1 = data1.fillna(0)\n",
    "\n",
    "    y.y_act = y.y_act.astype(float)\n",
    "    \n",
    "    return data1\n",
    "\n",
    "vectorizerName = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "vectorizerSample = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "\n",
    "def FeatureExtraction(data,data1,flag):\n",
    "\n",
    "    arr = data['Attribute_name'].values\n",
    "    arr = [str(x) for x in arr]\n",
    "    \n",
    "    arr1 = data['sample_1'].values\n",
    "    arr1 = [str(x) for x in arr1]\n",
    "    arr2 = data['sample_2'].values\n",
    "    arr2 = [str(x) for x in arr2]\n",
    "    arr3 = data['sample_3'].values\n",
    "    arr3 = [str(x) for x in arr3]    \n",
    "    print(len(arr1),len(arr2))\n",
    "    if flag:\n",
    "        X = vectorizerName.fit_transform(arr)\n",
    "        X1 = vectorizerSample.fit_transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)   \n",
    "    else:\n",
    "        X = vectorizerName.transform(arr)\n",
    "        X1 = vectorizerSample.transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)        \n",
    "        \n",
    "#     print(f\"> Length of vectorized feature_names: {len(vectorizer.get_feature_names())}\")\n",
    "\n",
    "    attr_df = pd.DataFrame(X.toarray())\n",
    "    sample1_df = pd.DataFrame(X1.toarray())\n",
    "    sample2_df = pd.DataFrame(X2.toarray())\n",
    "    print(len(data1),len(attr_df),len(sample1_df),len(sample2_df))\n",
    "\n",
    "    if useSample1: data2 = sample1_df\n",
    "    if useSample2: data2 = sample2_df    \n",
    "    \n",
    "    data2 = pd.concat([data1, attr_df], axis=1, sort=False)\n",
    "    print(len(data2))\n",
    "    return data2\n",
    "\n",
    "xtrain1 = ProcessStats(xtrain,y_train)\n",
    "xtest1 = ProcessStats(xtest,y_test)\n",
    "\n",
    "\n",
    "X_train = FeatureExtraction(xtrain,xtrain1,1)\n",
    "X_test = FeatureExtraction(xtest,xtest1,0)\n",
    "\n",
    "\n",
    "X_train_new = X_train.reset_index(drop=True)\n",
    "y_train_new = y_train.reset_index(drop=True)\n",
    "X_train_new = X_train_new.values\n",
    "y_train_new = y_train_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ORxyCh0VqoI",
    "outputId": "9bf5f989-0cf2-4c6c-9ff9-db3e5a65246a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 3. 3. 3.]\n",
      "train acc. : 0.9731602822580645\n",
      "test  acc. : 0.926448362720403\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.predict(X_train_new))\n",
    "\n",
    "print(\"train acc. :\",loaded_model.score(X_train_new, y_train))\n",
    "print(\"test  acc. :\",loaded_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O-QHTlpgVqoJ",
    "outputId": "5df9f20e-e8f1-444e-f04f-89e7d4451fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21477, 0, 0.0, 174, 0.810169018, 0.0, 0.0, 0.0, 0.0, False, False, False, False, 1.4, 0.8, 0.2, 0.4, 10.0, 4.816637832, 0.4, 0.8, 0.4, 0.8, False, False, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in X_train_new[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fo3dB9NMbaLn",
    "outputId": "1fa7642d-cd31-414d-fe46-e81b92499dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2VjodBfxVqoJ"
   },
   "outputs": [],
   "source": [
    "# keep_percent = 0.2\n",
    "query_sizes = [250,500] #[5, 10, 25, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_4IDabKiGA8",
    "outputId": "3973ab2b-bf9f-4735-856b-9c0b15113482"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5158, Simulation set size: 2778, Test set size: 1985\n",
      "[n_estimator: 100, max_depth: 100, accuracy: 0.9224181360201511]\n",
      "[n_estimator: 100, max_depth: 500, accuracy: 0.9224181360201511]\n",
      "[n_estimator: 100, max_depth: 1000, accuracy: 0.9224181360201511]\n",
      "[n_estimator: 500, max_depth: 100, accuracy: 0.9259445843828715]\n",
      "[n_estimator: 500, max_depth: 500, accuracy: 0.9259445843828715]\n",
      "[n_estimator: 500, max_depth: 1000, accuracy: 0.9259445843828715]\n",
      "[BEST OBTAINED RF ESTIMATOR] === [n_estimator: 500, max_depth: 100, accuracy: 0.9259445843828715]\n",
      "Time taken to obtain best AL learner with RF estimator 277.7266535758972\n",
      "\n",
      ">>>>>>>>>>>>>> [NEW ITERATION WITH NEXT QUERY SIZE] The total number of queries: 11 <<<<<<<<<<<<<<\n",
      "\n",
      "[INITIAL] Unqueried score before the AL teaching on TRAIN set: 0.9998061264055835\n",
      "[INITIAL] Unqueried score before the AL teaching on TEST set: 0.9259445843828715\n",
      "\n",
      "*********** QUERY 1 ***********\n",
      "\n",
      "Length of simulation set in query 1 is: 2778\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "with warnings.catch_warnings(record=\"True\"):\n",
    "    # ##### Version 1: Split test set into simulation set and actual test set\n",
    "    # simulation_idx = np.random.choice(len(X_test), int(len(X_test)/2), replace=False)\n",
    "    # test_idx = [i for i in range(len(X_test)) if i not in simulation_idx]\n",
    "    # X_simulation_AL = []\n",
    "    # y_simulation_AL = []\n",
    "    # for idx in simulation_idx:\n",
    "    #   X_simulation_AL.append(X_test.iloc[idx]) \n",
    "    #   y_simulation_AL.append(y_test.iloc[idx])\n",
    "\n",
    "    # X_test_AL = []\n",
    "    # y_test_AL = []\n",
    "    # for idx in test_idx:\n",
    "    #   X_test_AL.append(X_test.iloc[idx]) \n",
    "    #   y_test_AL.append(y_test.iloc[idx])\n",
    "\n",
    "    ##### Version 2: Reduce train set from 7936 to 6000 - use the remaining 1936 samples for AL and use the test set as is (1936/7936 ~= 24.39 %)\n",
    "    X_train_AL, X_simulation_AL, y_train_AL, y_simulation_AL = train_test_split(X_train_new, y_train, test_size=0.35, random_state=4, stratify=y_train, shuffle=True)\n",
    "\n",
    "    # Start AL loops simulated with a part of the test data\n",
    "    X_simulation_df = pd.DataFrame(X_simulation_AL)\n",
    "    y_simulation_df = pd.DataFrame(y_simulation_AL)\n",
    "\n",
    "    # making copies of existing X_test and y_test data\n",
    "    X_test_AL = pd.DataFrame(X_test)\n",
    "    y_test_AL = pd.DataFrame(y_test)\n",
    "\n",
    "    print(f\"Training set size: {len(X_train_AL)}, Simulation set size: {len(X_simulation_df)}, Test set size: {len(X_test_AL)}\")\n",
    "\n",
    "  # X_simulation_df = X_simulation_df.reset_index(drop=True)\n",
    "    for query_size in query_sizes:\n",
    "        model_accuracies = []\n",
    "        time_history = []\n",
    "        feed_to_learner = []\n",
    "\n",
    "        preset_batch = partial(uncertainty_batch_sampling, n_instances=query_size)\n",
    "        learners = []\n",
    "        n_estimators_grid = [100, 500]\n",
    "        max_depth_grid = [100, 500, 1000]\n",
    "        best_model_score = 0\n",
    "        best_model_idx = 0\n",
    "\n",
    "        pick_best_model_t0 = time.time()\n",
    "        # picking the best model after doing hyperparam tuning (normal grid search)\n",
    "        for ne in n_estimators_grid:\n",
    "            for md in max_depth_grid:\n",
    "                learner = ActiveLearner(\n",
    "                      estimator=RandomForestClassifier(n_estimators=ne, max_depth=md, random_state=100),\n",
    "                      X_training=X_train_AL, y_training=y_train_AL,\n",
    "                      query_strategy=preset_batch\n",
    "                    )\n",
    "                score = learner.score(X_test_AL, y_test_AL)\n",
    "                print(f\"[n_estimator: {ne}, max_depth: {md}, accuracy: {score}]\")\n",
    "                if best_model_score < score:\n",
    "                    best_ne = ne\n",
    "                    best_md = md\n",
    "                    best_model_score = score\n",
    "                    bestPerformingModel = learner\n",
    "\n",
    "        print(f\"[BEST OBTAINED RF ESTIMATOR] === [n_estimator: {best_ne}, max_depth: {best_md}, accuracy: {best_model_score}]\")\n",
    "        pick_best_model_t1 = time.time()\n",
    "        print(f\"Time taken to obtain best AL learner with RF estimator {pick_best_model_t1 - pick_best_model_t0}\")\n",
    "        num_of_queries = int(len(X_simulation_df)/query_size)\n",
    "        print(f\"\\n>>>>>>>>>>>>>> [NEW ITERATION WITH NEXT QUERY SIZE] The total number of queries: {num_of_queries} <<<<<<<<<<<<<<\\n\")\n",
    "\n",
    "        unqueried_score = learner.score(X_test_AL, y_test_AL)\n",
    "        unqueried_score_train = learner.score(X_train_AL, y_train_AL)\n",
    "        model_accuracies.append(unqueried_score)\n",
    "        print(f\"[INITIAL] Unqueried score before the AL teaching on TRAIN set: {unqueried_score_train}\")\n",
    "        print(f\"[INITIAL] Unqueried score before the AL teaching on TEST set: {unqueried_score}\")\n",
    "\n",
    "        query_size_t0 = time.time()\n",
    "        for i in range(num_of_queries):\n",
    "            print(f\"\\n*********** QUERY {i+1} ***********\\n\")\n",
    "            query_t0 = time.time()\n",
    "            print(f\"Length of simulation set in query {i+1} is: {len(X_simulation_df)}\")\n",
    "            query_idx, query_inst = learner.query(np.array(X_simulation_df))\n",
    "            print(f\"Nodes returned for query in iteration {i}: {query_idx}\")\n",
    "            learner.teach(X = X_simulation_df.iloc[query_idx], y = y_simulation_df.iloc[query_idx])\n",
    "            feed_to_learner.append(list(query_idx))\n",
    "\n",
    "            # delete queries that have been looped back into the model\n",
    "            X_simulation_df = X_simulation_df.drop(X_simulation_df.index[query_idx])\n",
    "            y_simulation_df = y_simulation_df.drop(y_simulation_df.index[query_idx])\n",
    "\n",
    "            # learner.teach(X = pd.Series(X_simulation_np[idx]), y = y_simulation_np[idx])\n",
    "\n",
    "            # X_simulation_np = np.delete(X_simulation_np, query_index, axis=0)\n",
    "            # y_simulation_np = np.delete(y_simulation_np, query_index)\n",
    "\n",
    "            # Calculate and report our model's accuracy.\n",
    "            model_accuracy = learner.score(X_test_AL, y_test_AL)\n",
    "            model_accuracies.append(model_accuracy)\n",
    "            \n",
    "            query_t1 = time.time()\n",
    "            time_history.append(query_t1 - query_t0)\n",
    "            print(f\"\\n[INTERMEDIATE] Accuracy after query {i+1}: {model_accuracy:0.4f}\")\n",
    "            print(f\"\\n[INTERMEDIATE] Time taken for query {i+1}: {query_t1 - query_t0}\")\n",
    "\n",
    "        print(f\"\\n[FINAL] Accuracy after query {num_of_queries}: {model_accuracies[-1]:0.4f}\")\n",
    "        print(f\"\\n[FINAL-HIGHEST] OPTIMAL Accuracy obtained: {max(model_accuracies):0.4f}\")\n",
    "        print(f\"\\n[FINAL ACCURACY LIST]: {model_accuracies}\")\n",
    "        query_size_t1 = time.time()\n",
    "        print(f\"\\n[TIME TAKEN]: {query_size_t1 - query_size_t0}\")\n",
    "        print(f\"\\n[FINAL FEED TO LEARNER LIST]: {len(feed_to_learner)}, {feed_to_learner}\")\n",
    "\n",
    "        prefix = \"uncertainty_batch_sampling\"\n",
    "        np.savetxt(f\"./img/feed_history_{prefix}__ne{best_ne}_md{best_md}_qs{query_size}.csv\", feed_to_learner, delimiter =\", \", fmt ='% s')\n",
    "        np.savetxt(f\"./img/acc_history_{prefix}__ne{best_ne}_md{best_md}_qs{query_size}.csv\", model_accuracies, delimiter =\", \", fmt ='% s')\n",
    "        np.savetxt(f\"./img/time_history_{prefix}__ne{best_ne}_md{best_md}_qs{query_size}.csv\", time_history, delimiter =\", \", fmt ='% s')\n",
    "        plt.plot([1] + [i+1 for i in range(1, num_of_queries + 1)], model_accuracies)\n",
    "        plt.xlabel(\"Queries\")\n",
    "        plt.ylabel(\"Model accuracy on test set\")\n",
    "        plt.savefig(f\"./img/{prefix}_ne{best_ne}_md{best_md}_qs{query_size}.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPGdpgmqrEIM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_234_v2.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
