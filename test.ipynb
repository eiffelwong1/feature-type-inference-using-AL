{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(7936, 33)\n(1985, 33)\nIndex(['Record_id', 'Attribute_name', 'y_act', 'total_vals', 'num_nans',\n       '%_nans', 'num_of_dist_val', '%_dist_val', 'mean', 'std_dev', 'min_val',\n       'max_val', 'sample_1', 'sample_2', 'sample_3', 'sample_4', 'sample_5',\n       'has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count',\n       'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total',\n       'mean_char_count', 'stdev_char_count', 'mean_whitespace_count',\n       'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count',\n       'is_list', 'is_long_sentence'],\n      dtype='object')\n"
    }
   ],
   "source": [
    "xtrain = pd.read_csv('ML-Data-Prep-Zoo/MLFeatureTypeInference/Benchmark-Labeled-Data/data_train.csv')\n",
    "xtest = pd.read_csv('ML-Data-Prep-Zoo/MLFeatureTypeInference/Benchmark-Labeled-Data/data_test.csv')\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(xtrain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filePathName = 'ML-Data-Prep-Zoo/MLFeatureTypeInference/Pre-trained Models/RandomForest.pkl'\n",
    "loaded_model = pickle.load(open(filePathName, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "useStats = 1\n",
    "useAttributeName = 1\n",
    "useSample1 = 0\n",
    "useSample2 = 0\n",
    "## Using descriptive stats and attribute name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label = {\n",
    "    'numeric': 0,\n",
    "    'categorical': 1,\n",
    "    'datetime': 2,\n",
    "    'sentence': 3,\n",
    "    'url': 4,\n",
    "    'embedded-number': 5,\n",
    "    'list': 6,\n",
    "    'not-generalizable': 7,\n",
    "    'context-specific': 8\n",
    "}\n",
    "\n",
    "y_train = xtrain.loc[:,['y_act']]\n",
    "y_test = xtest.loc[:,['y_act']]\n",
    "y_train['y_act'] = [dict_label[i] for i in y_train['y_act']]\n",
    "y_test['y_act'] = [dict_label[i] for i in y_test['y_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "7936 7936\n7936 7936 7936 7936\n7936\n1985 1985\n1985 1985 1985 1985\n1985\n"
    }
   ],
   "source": [
    "def ProcessStats(data,y):\n",
    "\n",
    "    data1 = data[['total_vals', 'num_nans', '%_nans', 'num_of_dist_val', '%_dist_val', 'mean', 'std_dev', 'min_val', 'max_val','has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count',\n",
    "       'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total',\n",
    "       'mean_char_count', 'stdev_char_count', 'mean_whitespace_count',\n",
    "       'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count',\n",
    "       'is_list', 'is_long_sentence']]\n",
    "    data1 = data1.reset_index(drop=True)\n",
    "    data1 = data1.fillna(0)\n",
    "\n",
    "    y.y_act = y.y_act.astype(float)\n",
    "    \n",
    "    return data1\n",
    "\n",
    "vectorizerName = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "vectorizerSample = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "\n",
    "def FeatureExtraction(data,data1,flag):\n",
    "\n",
    "    arr = data['Attribute_name'].values\n",
    "    arr = [str(x) for x in arr]\n",
    "    \n",
    "    arr1 = data['sample_1'].values\n",
    "    arr1 = [str(x) for x in arr1]\n",
    "    arr2 = data['sample_2'].values\n",
    "    arr2 = [str(x) for x in arr2]\n",
    "    arr3 = data['sample_3'].values\n",
    "    arr3 = [str(x) for x in arr3]    \n",
    "    print(len(arr1),len(arr2))\n",
    "    if flag:\n",
    "        X = vectorizerName.fit_transform(arr)\n",
    "        X1 = vectorizerSample.fit_transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)   \n",
    "    else:\n",
    "        X = vectorizerName.transform(arr)\n",
    "        X1 = vectorizerSample.transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)        \n",
    "        \n",
    "#     print(f\"> Length of vectorized feature_names: {len(vectorizer.get_feature_names())}\")\n",
    "\n",
    "    attr_df = pd.DataFrame(X.toarray())\n",
    "    sample1_df = pd.DataFrame(X1.toarray())\n",
    "    sample2_df = pd.DataFrame(X2.toarray())\n",
    "    print(len(data1),len(attr_df),len(sample1_df),len(sample2_df))\n",
    "\n",
    "    if useSample1: data2 = sample1_df\n",
    "    if useSample2: data2 = sample2_df    \n",
    "    \n",
    "    data2 = pd.concat([data1, attr_df], axis=1, sort=False)\n",
    "    print(len(data2))\n",
    "    return data2\n",
    "\n",
    "xtrain1 = ProcessStats(xtrain,y_train)\n",
    "xtest1 = ProcessStats(xtest,y_test)\n",
    "\n",
    "\n",
    "X_train = FeatureExtraction(xtrain,xtrain1,1)\n",
    "X_test = FeatureExtraction(xtest,xtest1,0)\n",
    "\n",
    "\n",
    "X_train_new = X_train.reset_index(drop=True)\n",
    "y_train_new = y_train.reset_index(drop=True)\n",
    "X_train_new = X_train_new.values\n",
    "y_train_new = y_train_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1. 1. 1. ... 3. 3. 3.]\n"
    }
   ],
   "source": [
    "print(loaded_model.predict(X_train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}